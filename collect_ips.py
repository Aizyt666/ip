# å¯¼å…¥å¿…è¦æ¨¡å—
import requests  # ç”¨äºå‘é€ç½‘ç»œè¯·æ±‚
from bs4 import BeautifulSoup  # ç”¨äºè§£æ HTML ç½‘é¡µ
import re  # ç”¨äºå¤„ç†æ­£åˆ™è¡¨è¾¾å¼
import os  # ç”¨äºæ–‡ä»¶æ“ä½œ
from concurrent.futures import ThreadPoolExecutor, as_completed  # å®ç°å¤šçº¿ç¨‹å¹¶å‘

# å®šä¹‰ç›®æ ‡ç½‘ç«™åˆ—è¡¨
urls = [
    'https://api.uouin.com/cloudflare.html',
    'https://ip.164746.xyz',
    'https://cf.vvhan.com/'
]

# ç”¨äºåŒ¹é… IPv4 çš„æ­£åˆ™è¡¨è¾¾å¼
ip_pattern = r'\d{1,3}(?:\.\d{1,3}){3}'

# åˆ¤æ–­ä¸€ä¸ª IP åœ°å€æ˜¯å¦æœ‰æ•ˆï¼ˆæ ¼å¼ + èŒƒå›´ + æ’é™¤ç‰¹æ®Š IPï¼‰
def is_valid_ip(ip):
    parts = ip.split('.')
    if len(parts) != 4:
        return False
    for part in parts:
        if not part.isdigit():
            return False
        num = int(part)
        if num < 0 or num > 255:
            return False
    if ip in ('0.0.0.0', '127.0.0.1', '255.255.255.255'):
        return False
    return True

# æŠ“å–æŸä¸ª URL çš„ IP åˆ—è¡¨ï¼Œæ”¯æŒå¤šçº¿ç¨‹
def fetch_ips(url):
    ip_list = []  # å­˜æ”¾å½“å‰ç½‘å€æå–åˆ°çš„åˆæ³• IP
    try:
        print(f'ğŸ” æ­£åœ¨è¯·æ±‚ï¼š{url}')
        response = requests.get(url, timeout=10)  # è®¾ç½®è¶…æ—¶æ—¶é—´ä¸º10ç§’
        soup = BeautifulSoup(response.text, 'html.parser')  # è§£æ HTML å†…å®¹

        # å¤„ç† vvhan ç½‘ç«™ï¼ŒIP é€šå¸¸åœ¨ <textarea class="form-control"> ä¸­
        if url == 'https://cf.vvhan.com/':
            textarea = soup.find('textarea', class_='form-control')
            if textarea:
                lines = textarea.get_text().strip().splitlines()  # æ¯è¡Œå¯èƒ½æ˜¯ä¸€ä¸ª IP
                for line in lines:
                    ip_list.extend(re.findall(ip_pattern, line))

        # å¤„ç†å¦å¤–ä¸¤ä¸ªç½‘ç«™ï¼ŒIP åœ¨è¡¨æ ¼çš„æ¯ä¸€è¡Œä¸­
        elif url in ('https://api.uouin.com/cloudflare.html', 'https://ip.164746.xyz'):
            elements = soup.find_all('tr')
            for el in elements:
                text = el.get_text().strip()
                ip_list.extend(re.findall(ip_pattern, text))

        # å…¶ä»–é»˜è®¤å¤„ç†æ–¹å¼ï¼Œå°è¯•ä» <li> å…ƒç´ ä¸­æå– IP
        else:
            elements = soup.find_all('li')
            for el in elements:
                text = el.get_text().strip()
                ip_list.extend(re.findall(ip_pattern, text))

        # è¿‡æ»¤æ‰æ— æ•ˆ IP
        ip_list = [ip for ip in ip_list if is_valid_ip(ip)]

        print(f'âœ… æˆåŠŸæå– {len(ip_list)} ä¸ª IP æ¥è‡ªï¼š{url}')
        return ip_list

    except requests.exceptions.RequestException as e:
        print(f'âš ï¸ è¯·æ±‚å¤±è´¥ï¼š{url} â€”â€” {e}')
    except Exception as e:
        print(f'âš ï¸ æœªçŸ¥é”™è¯¯ï¼š{url} â€”â€” {e}')
    return []  # å‡ºé”™æ—¶è¿”å›ç©ºåˆ—è¡¨

# åˆ é™¤æ—§çš„ ip.txt æ–‡ä»¶
if os.path.exists('ip.txt'):
    os.remove('ip.txt')

# åˆ›å»ºé›†åˆç”¨äºå»é‡
all_ips = set()

# ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘è¯·æ±‚æ‰€æœ‰ URL
with ThreadPoolExecutor(max_workers=5) as executor:
    # æäº¤æ‰€æœ‰ä»»åŠ¡
    future_to_url = {executor.submit(fetch_ips, url): url for url in urls}
    
    # ç­‰å¾…ä»»åŠ¡å®Œæˆ
    for future in as_completed(future_to_url):
        url = future_to_url[future]
        try:
            ips = future.result()
            all_ips.update(ips)  # æ·»åŠ åˆ°é›†åˆï¼ˆè‡ªåŠ¨å»é‡ï¼‰
        except Exception as e:
            print(f'âŒ æŠ“å–å¤±è´¥ï¼ˆ{url}ï¼‰ï¼š{e}')

# å†™å…¥ IP åˆ° ip.txt æ–‡ä»¶å¹¶æ‰“å°
try:
    with open('ip.txt', 'w') as file:
        for ip in sorted(all_ips):  # æ’åºå†™å…¥
            file.write(ip + '\n')
            print(f'ğŸ“¥ å†™å…¥ IPï¼š{ip}')
    print(f'ğŸ‰ æ€»å…±æå– {len(all_ips)} ä¸ªæœ‰æ•ˆ IPï¼Œå·²ä¿å­˜åˆ° ip.txtã€‚')
except Exception as e:
    print(f'âŒ å†™å…¥æ–‡ä»¶å¤±è´¥ï¼š{e}')
