# å¯¼å…¥å¿…è¦æ¨¡å—
import requests  # ç”¨äºå‘é€ HTTP è¯·æ±‚
from bs4 import BeautifulSoup  # ç”¨äºè§£æ HTML é¡µé¢
import re  # æ­£åˆ™è¡¨è¾¾å¼æ¨¡å—ï¼Œç”¨äºæå– IP
import os  # æ“ä½œç³»ç»Ÿæ¨¡å—ï¼Œç”¨äºæ–‡ä»¶æ“ä½œ
from concurrent.futures import ThreadPoolExecutor, as_completed  # ç”¨äºå®ç°å¤šçº¿ç¨‹

# å®šä¹‰ç›®æ ‡ç½‘é¡µåˆ—è¡¨ï¼Œè¿™äº›ç½‘é¡µåŒ…å« Cloudflare çš„ IP æ•°æ®
urls = [
    'https://api.uouin.com/cloudflare.html',
    'https://ip.164746.xyz',
    'https://cf.vvhan.com/'
]

# å®šä¹‰ IPv4 åŒ¹é…æ­£åˆ™è¡¨è¾¾å¼
ip_pattern = r'\d{1,3}(?:\.\d{1,3}){3}'

# å®šä¹‰å‡½æ•°ï¼šåˆ¤æ–­ IP åœ°å€æ˜¯å¦åˆæ³•
def is_valid_ip(ip):
    parts = ip.split('.')  # æŒ‰ . åˆ†å‰²ä¸ºå››æ®µ
    if len(parts) != 4:
        return False
    for part in parts:
        if not part.isdigit():
            return False
        num = int(part)
        if num < 0 or num > 255:
            return False
    # æ’é™¤ä¸€äº›æ— æ•ˆåœ°å€
    if ip in ('0.0.0.0', '127.0.0.1', '255.255.255.255'):
        return False
    return True

# å®šä¹‰å‡½æ•°ï¼šä»æŒ‡å®š URL ä¸­æå– IP åœ°å€
def fetch_ips(url):
    ip_list = []  # å½“å‰ç½‘ç«™æå–çš„ IP åˆ—è¡¨
    try:
        print(f'ğŸ” æ­£åœ¨è¯·æ±‚ï¼š{url}')  # æç¤ºè¯·æ±‚å¼€å§‹
        response = requests.get(url, timeout=10)  # 10 ç§’è¶…æ—¶ï¼Œé˜²æ­¢å¡æ­»
        soup = BeautifulSoup(response.text, 'html.parser')  # è§£æ HTML

        # å¤„ç† cf.vvhan.com é¡µé¢ï¼ŒIP åœ¨ <td> ä¸­
        if url == 'https://cf.vvhan.com/':
            elements = soup.find_all('td')  # æŸ¥æ‰¾æ‰€æœ‰ td æ ‡ç­¾
            for el in elements:
                text = el.get_text(strip=True)
                ip_list.extend(re.findall(ip_pattern, text))

        # å¤„ç†å…¶ä»–ä¸¤ä¸ªç½‘é¡µï¼ŒIP åœ¨ <tr> æ ‡ç­¾ä¸­
        elif url in ('https://api.uouin.com/cloudflare.html', 'https://ip.164746.xyz'):
            elements = soup.find_all('tr')  # æŸ¥æ‰¾æ‰€æœ‰è¡¨æ ¼è¡Œ
            for el in elements:
                text = el.get_text(strip=True)
                ip_list.extend(re.findall(ip_pattern, text))

        # é»˜è®¤å¤„ç†æ–¹å¼ï¼šæŸ¥æ‰¾ <li> æ ‡ç­¾
        else:
            elements = soup.find_all('li')
            for el in elements:
                text = el.get_text(strip=True)
                ip_list.extend(re.findall(ip_pattern, text))

        # è¿‡æ»¤æ‰æ— æ•ˆ IP
        ip_list = [ip for ip in ip_list if is_valid_ip(ip)]

        print(f'âœ… æˆåŠŸæå– {len(ip_list)} ä¸ª IP æ¥è‡ªï¼š{url}')
        return ip_list  # è¿”å›åˆæ³• IP åˆ—è¡¨

    except requests.exceptions.RequestException as e:
        print(f'âš ï¸ è¯·æ±‚å¤±è´¥ï¼š{url} â€”â€” {e}')  # è¯·æ±‚é”™è¯¯
    except Exception as e:
        print(f'âš ï¸ æœªçŸ¥é”™è¯¯ï¼š{url} â€”â€” {e}')  # å…¶å®ƒé”™è¯¯
    return []  # è¿”å›ç©ºåˆ—è¡¨é˜²æ­¢ç¨‹åºä¸­æ–­

# åˆ é™¤æ—§æ–‡ä»¶ ip.txtï¼ˆå¦‚æœå­˜åœ¨ï¼‰
if os.path.exists('ip.txt'):
    os.remove('ip.txt')

# ä½¿ç”¨é›†åˆå­˜å‚¨æ‰€æœ‰ IPï¼Œè‡ªåŠ¨å»é‡
all_ips = set()

# å¯ç”¨çº¿ç¨‹æ± å¹¶å‘è¯·æ±‚ï¼Œæå‡æŠ“å–æ•ˆç‡
with ThreadPoolExecutor(max_workers=5) as executor:
    # æäº¤æ‰€æœ‰ URL æŠ“å–ä»»åŠ¡
    future_to_url = {executor.submit(fetch_ips, url): url for url in urls}

    # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
    for future in as_completed(future_to_url):
        url = future_to_url[future]
        try:
            ips = future.result()  # è·å–ç»“æœ
            all_ips.update(ips)  # æ·»åŠ åˆ°æ€»é›†åˆä¸­ï¼ˆè‡ªåŠ¨å»é‡ï¼‰
        except Exception as e:
            print(f'âŒ æŠ“å–å¤±è´¥ï¼ˆ{url}ï¼‰ï¼š{e}')  # æŠ¥é”™æç¤º

# å†™å…¥æ‰€æœ‰ IP åˆ° ip.txt æ–‡ä»¶
try:
    with open('ip.txt', 'w') as file:
        for ip in sorted(all_ips):  # æ’åºåå†™å…¥
            file.write(ip + '\n')
            print(f'ğŸ“¥ å†™å…¥ IPï¼š{ip}')
    print(f'ğŸ‰ æ€»å…±æå– {len(all_ips)} ä¸ªæœ‰æ•ˆ IPï¼Œå·²ä¿å­˜åˆ° ip.txtã€‚')
except Exception as e:
    print(f'âŒ å†™å…¥æ–‡ä»¶å¤±è´¥ï¼š{e}')
